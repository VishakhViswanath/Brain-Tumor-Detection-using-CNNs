{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a8943c",
   "metadata": {},
   "source": [
    "# Brain-Tumor-Image-Classification-Machine-Learning-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57766cb7",
   "metadata": {},
   "source": [
    "In this ML project we will create an ML model that can detect and classify brain tumors by image recognition. We will use scanned MRIs of healthy and unhealthy brains to train the model. By using the Image classification our model will be able to classify brain scans as Helathy and Unhealthy.\n",
    "\n",
    "We have 4600 scanned images of healthy and unhealthy brains sectioned into two folders Healthy and Unhealthy, Our model will have to classify each scan to respective Tumor and No Tumor categories.\n",
    "\n",
    "The dataset is from Kaggle's brain-tumor-dataset.\n",
    "\n",
    "We will use CNNs for model building by making use of Binary Image Classification\n",
    "\n",
    "Binary Image Classification: Binary classification involves classifying images into one of two categories. For example, determining whether an image contains a cat or not in our case Healthy & Unhealthy brain. This is the simplest form of image classification.\n",
    "\n",
    "For the classifiaction algorithm we will use the TensorFlow platform and Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621870ba",
   "metadata": {},
   "source": [
    "# Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbcf35ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d87f6553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img # reading the image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # reads the image from database \n",
    "# tf.config.experimental_run_functions_eagerly(True)\n",
    "# tf.data.experimental.enable_debug_mode(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd411a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"/Users/asus/Documents/DS/## 180 Projects/PROJECTS/Brain tumor project/hands/Brain Tumor Data Set/Brain Tumor Data Set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf9954",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 150\n",
    "input_shape = (150,150,1) # shape of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c9aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(rescale=1./255,\n",
    "                             validation_split=0.2) #Normalizing the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef3d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset\n",
    "train_gen = data_gen.flow_from_directory(img_dir,\n",
    "                                        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                        batch_size= BATCH_SIZE,\n",
    "                                        color_mode = \"grayscale\",\n",
    "                                        shuffle=True,\n",
    "                                        class_mode = \"binary\",\n",
    "                                        subset= \"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42429fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Dataset\n",
    "val_gen = data_gen.flow_from_directory(img_dir,\n",
    "                                      target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      color_mode = \"grayscale\",\n",
    "                                      shuffle=False,\n",
    "                                       class_mode = \"binary\",\n",
    "                                       subset=\"validation\"\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6d7da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_gen.class_indices #(an index allowing documents to be indexed, deleted, and searched)\n",
    "classes = list(labels.keys())\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1189f53",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe95f050",
   "metadata": {},
   "source": [
    "For the modelling purposes we will use a convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4d7961",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks.\n",
    "\n",
    "* CNNs are very similar to ordinary Neural Networks, they are made up of neurons that have learnable weights and biases. Each neuron receives some input, performs a dot product and optionally follows it with a non-linearity.\n",
    "\n",
    "* CNNs forward propagation efficient and vastly reduces the number of parameters in the network\n",
    "\n",
    "### Layers\n",
    "\n",
    "* Input layer will hold the raw pixel values of the image, having the shape of (W,H,D).D denotes depth whether RGB(3), Grayscale(1),etc.\n",
    "\n",
    "* CONV layer will compute the output of neurons that are connected to local regions in the input, each computing a dot product b/w their weights and a small region.\n",
    "\n",
    "* RELU is the activation function, The rectified linear unit (ReLU) or rectifier activation function introduces the property of nonlinearity to a deep learning model and solves the vanishing gradients issue. It interprets the positive part of its argument.\n",
    "\n",
    "* POOLING layer will perform a down-sampling operation along the spatial dimensions(W,H)\n",
    "\n",
    "* Fully connected layer will compute the class scores as in a regular neural network, As with ordinary Neural Networks and as the name implies, each neuron in this layer will be connected to all the numbers in the previous volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a067910",
   "metadata": {},
   "source": [
    "# Implementing CNN\n",
    "\n",
    "* We will use TensorFlow and the Keras API for implementation\n",
    "* We will add 2 layers of convolutional layers along with 2 Max Pooling layers.\n",
    "* Our dense layer will have 512 neurons, Our input layer wil be defining the size of image being fed into the network and an output layer will be having one neuron since it is a classifiaction problem\n",
    "* Saving the model and deployment of Flask Webapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b6113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  Sequential()\n",
    "\n",
    "model.add(keras.layers.InputLayer(input_shape = (150,150,1)))\n",
    "model.add(Conv2D(16,(3,3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(32,(3,3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddb2624",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "             loss = \"binary_crossentropy\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9d103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba91f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1da663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'): # using the GPU\n",
    "    history = model.fit(train_gen,\n",
    "                        verbose = 1,\n",
    "                        epochs=5,\n",
    "                        validation_data= val_gen,\n",
    "                        steps_per_epoch= 3681//64,\n",
    "                        validation_steps = 919//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca349e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc =  model.evaluate(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8817e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, \"y\", label = \"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'r', label = \"Validation loss\")\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc =  history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "plt.plot(epochs, acc, 'y', label = \"Training acc\")\n",
    "plt.plot(epochs, val_acc, 'r', label = \"Validation acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d119d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"model.h5\")\n",
    "model.save(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4356c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "data = np.ndarray(shape = (1,150,150,1), dtype = np.float32)\n",
    "image= Image.open(f'/Users/asus/Documents/DS/## 180 Projects/PROJECTS/Brain tumor project/hands/Brain Tumor Data Set/Brain Tumor Data Set/Healthy/Not Cancer  (39).jpg')\n",
    "#image = Image.open(f'/Users/asus/Documents/DS/## 180 Projects/PROJECTS/Brain tumor project/hands/Brain Tumor Data Set/Brain Tumor Data Set/Brain Tumor/Cancer (25).tif')\n",
    "size = (150,150)\n",
    "image = ImageOps.grayscale(image)\n",
    "image = ImageOps.fit(image, size)\n",
    "image_array = np.asarray(image)\n",
    "display(image)\n",
    "\n",
    "# normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "data = image_array.reshape((-1,150,150,1))\n",
    "\n",
    "#data[0] = normalized_image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f1e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction =  model.predict(data)\n",
    "print(prediction[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002b6849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-TFenv]",
   "language": "python",
   "name": "conda-env-.conda-TFenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
